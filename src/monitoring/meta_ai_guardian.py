"""
Mindframe Meta-AI Guardian
Self-improving, self-healing, self-monitoring AI system

UNIQUE TO MINDFRAME - PRIVATE & PROPRIETARY:
- AI that monitors AI
- Automatic bug detection and fixes
- Performance optimization
- Security vulnerability scanning
- Code quality improvement
- Automatic dependency updates
- Self-improving agents
- AUTONOMOUS OPERATION WITH HUMAN CONTROL

This is YOUR competitive advantage. Keep it private!
"""
from typing import Dict, List, Optional, Any, Callable
from pydantic import BaseModel
from openai import AsyncOpenAI
from loguru import logger
from datetime import datetime, timedelta
from enum import Enum
import asyncio
import json


class SystemIssue(BaseModel):
    """Detected system issue"""
    id: str
    severity: str  # "critical", "high", "medium", "low"
    category: str  # "bug", "performance", "security", "quality"
    title: str
    description: str
    detected_at: datetime
    file_path: Optional[str] = None
    line_number: Optional[int] = None
    suggested_fix: Optional[str] = None
    auto_fixable: bool = False


class ImprovementSuggestion(BaseModel):
    """AI-generated improvement suggestion"""
    id: str
    type: str  # "performance", "code_quality", "feature", "security"
    title: str
    description: str
    impact: str  # "high", "medium", "low"
    effort: str  # "easy", "medium", "hard"
    code_diff: Optional[str] = None
    estimated_improvement: str  # "30% faster", "50% less bugs"


class SystemHealth(BaseModel):
    """Overall system health metrics"""
    timestamp: datetime
    health_score: float  # 0-100
    performance_score: float  # 0-100
    security_score: float  # 0-100
    quality_score: float  # 0-100
    issues_count: int
    critical_issues: int
    uptime_percentage: float
    avg_response_time_ms: float
    error_rate: float


class AutonomyLevel(str, Enum):
    """
    Control how much autonomy the AI has

    YOU ALWAYS HAVE FULL CONTROL - This just controls what AI does automatically
    """
    MANUAL = "manual"  # AI only suggests, NEVER acts automatically
    SUPERVISED = "supervised"  # AI can fix low-risk issues, asks for critical
    SEMI_AUTONOMOUS = "semi_autonomous"  # AI fixes most issues, logs everything
    FULLY_AUTONOMOUS = "fully_autonomous"  # AI fixes everything, unlimited power


class ApprovalStatus(str, Enum):
    """Status of actions requiring approval"""
    PENDING = "pending"  # Waiting for your approval
    APPROVED = "approved"  # You approved it
    REJECTED = "rejected"  # You rejected it
    AUTO_APPROVED = "auto_approved"  # Within autonomy level, auto-approved


class AIAction(BaseModel):
    """An action the AI wants to take"""
    id: str
    action_type: str  # "fix_bug", "optimize_code", "update_dependency", etc.
    title: str
    description: str
    risk_level: str  # "low", "medium", "high", "critical"
    affected_files: List[str]
    code_diff: Optional[str] = None
    estimated_impact: str
    requires_approval: bool = False
    approval_status: ApprovalStatus = ApprovalStatus.PENDING
    created_at: datetime
    approved_at: Optional[datetime] = None
    approved_by: Optional[str] = None


class ControlSettings(BaseModel):
    """
    Your control settings for Meta-AI Guardian

    YOU ARE IN CONTROL - Set exactly what AI can and cannot do
    """
    autonomy_level: AutonomyLevel = AutonomyLevel.SUPERVISED  # Default: supervised

    # What requires your approval?
    require_approval_for_critical: bool = True  # Always ask for critical issues
    require_approval_for_file_changes: bool = True  # Ask before changing files
    require_approval_for_dependencies: bool = True  # Ask before updating packages
    require_approval_for_new_features: bool = True  # Ask before adding features

    # Auto-approve rules (even in supervised mode)
    auto_approve_low_risk: bool = True  # Auto-fix typos, formatting, etc.
    auto_approve_security_patches: bool = False  # Ask even for security (you decide)

    # Monitoring settings
    monitoring_interval_minutes: int = 60  # Check every hour
    send_alerts: bool = True  # Alert you about issues
    alert_threshold: str = "high"  # Alert on: "low", "medium", "high", "critical"

    # Rollback settings
    enable_automatic_rollback: bool = True  # Auto-rollback if something breaks
    rollback_on_test_failure: bool = True  # Rollback if tests fail
    keep_backups_days: int = 30  # Keep file backups for 30 days


class MetaAIGuardian:
    """
    Meta-AI Guardian - The Vaktmester (Caretaker)

    This is YOUR secret weapon. Nobody else has this.
    AI that watches, learns, improves, and fixes your entire platform.

    **AUTONOMOUS BUT YOU ARE IN CONTROL**

    Capabilities:
    1. Monitor all systems 24/7
    2. Detect bugs automatically
    3. Fix issues (with your approval if needed)
    4. Optimize performance continuously
    5. Find security vulnerabilities
    6. Suggest and implement improvements
    7. Learn from all interactions
    8. Keep dependencies updated
    9. Prevent problems before they happen
    10. ASK FOR APPROVAL on critical decisions (you control this!)
    11. ROLLBACK changes if something breaks
    12. YOU CAN OVERRIDE EVERYTHING
    """

    def __init__(
        self,
        openai_api_key: str,
        control_settings: Optional[ControlSettings] = None,
        approval_callback: Optional[Callable] = None
    ):
        self.client = AsyncOpenAI(api_key=openai_api_key)
        self.model = "gpt-4-turbo-preview"
        self.issues: List[SystemIssue] = []
        self.improvements: List[ImprovementSuggestion] = []
        self.pending_actions: List[AIAction] = []
        self.is_monitoring = False

        # YOUR CONTROL SETTINGS
        self.control_settings = control_settings or ControlSettings()

        # Callback for approvals (e.g., send notification, show in UI)
        self.approval_callback = approval_callback

        # File backups for rollback
        self.file_backups: Dict[str, List[Dict]] = {}

    async def analyze_codebase(self, file_paths: List[str]) -> List[SystemIssue]:
        """
        Analyze codebase for bugs, security issues, performance problems

        This is like having a senior developer review ALL your code 24/7.
        """
        logger.info(f"üîç Meta-AI analyzing {len(file_paths)} files...")

        all_issues = []

        for file_path in file_paths:
            try:
                # Read file
                with open(file_path, 'r') as f:
                    code = f.read()

                # Ask GPT-4 to analyze
                prompt = f"""
Analyze this Python code for issues:

File: {file_path}

```python
{code[:5000]}  # First 5000 chars
```

Find:
1. Bugs (logic errors, edge cases, exceptions)
2. Security vulnerabilities (SQL injection, XSS, auth bypass)
3. Performance issues (N+1 queries, memory leaks, slow algorithms)
4. Code quality (duplicates, complexity, readability)

For EACH issue found, return JSON:
{{
    "severity": "critical|high|medium|low",
    "category": "bug|security|performance|quality",
    "title": "Brief issue title",
    "description": "Detailed explanation",
    "line_number": <line number if known>,
    "suggested_fix": "How to fix it",
    "auto_fixable": true/false
}}

Return array of issues. If no issues, return [].
"""

                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "You are Meta-AI Guardian, an expert code analyzer. Find ALL issues."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    response_format={"type": "json_object"},
                    temperature=0.3
                )

                result = json.loads(response.choices[0].message.content)
                issues_data = result.get("issues", [])

                # Create SystemIssue objects
                for issue_data in issues_data:
                    issue = SystemIssue(
                        id=f"issue_{datetime.now().timestamp()}",
                        severity=issue_data.get("severity", "medium"),
                        category=issue_data.get("category", "quality"),
                        title=issue_data.get("title", ""),
                        description=issue_data.get("description", ""),
                        detected_at=datetime.now(),
                        file_path=file_path,
                        line_number=issue_data.get("line_number"),
                        suggested_fix=issue_data.get("suggested_fix"),
                        auto_fixable=issue_data.get("auto_fixable", False)
                    )
                    all_issues.append(issue)

                logger.info(f"   ‚úÖ {file_path}: {len(issues_data)} issues found")

            except Exception as e:
                logger.error(f"   ‚ùå Error analyzing {file_path}: {e}")

        self.issues.extend(all_issues)

        # Log summary
        critical = sum(1 for i in all_issues if i.severity == "critical")
        high = sum(1 for i in all_issues if i.severity == "high")

        logger.info(
            f"üéØ Analysis complete: {len(all_issues)} total issues "
            f"({critical} critical, {high} high)"
        )

        return all_issues

    def _requires_approval(self, action: AIAction) -> bool:
        """
        Check if action requires your approval based on control settings

        YOU DECIDE what needs approval!
        """
        # Manual mode: EVERYTHING requires approval
        if self.control_settings.autonomy_level == AutonomyLevel.MANUAL:
            return True

        # Check specific approval rules
        if action.risk_level == "critical" and self.control_settings.require_approval_for_critical:
            return True

        if action.action_type == "fix_bug" and self.control_settings.require_approval_for_file_changes:
            return True

        if action.action_type == "update_dependency" and self.control_settings.require_approval_for_dependencies:
            return True

        if action.action_type == "add_feature" and self.control_settings.require_approval_for_new_features:
            return True

        # Auto-approve low-risk if enabled
        if action.risk_level == "low" and self.control_settings.auto_approve_low_risk:
            return False

        # Fully autonomous mode: nothing requires approval
        if self.control_settings.autonomy_level == AutonomyLevel.FULLY_AUTONOMOUS:
            return False

        # Default for supervised/semi-autonomous: approve high and critical
        return action.risk_level in ["high", "critical"]

    async def _request_approval(self, action: AIAction) -> bool:
        """
        Request approval for an action

        This ASKS YOU before doing something important
        """
        logger.info(f"ü§î Requesting approval for: {action.title}")

        # Add to pending actions
        self.pending_actions.append(action)

        # Call approval callback if provided (e.g., send notification)
        if self.approval_callback:
            await self.approval_callback(action)

        # In production: Wait for approval via API/UI
        # For now: Log and return False (wait for manual approval)
        logger.warning(f"‚è∏Ô∏è  Action paused, waiting for your approval: {action.id}")

        return False

    async def approve_action(self, action_id: str, approved_by: str = "user") -> bool:
        """
        Approve a pending action

        YOU APPROVE what AI can do
        """
        action = next((a for a in self.pending_actions if a.id == action_id), None)

        if not action:
            logger.error(f"Action {action_id} not found")
            return False

        action.approval_status = ApprovalStatus.APPROVED
        action.approved_at = datetime.now()
        action.approved_by = approved_by

        logger.info(f"‚úÖ Action approved by {approved_by}: {action.title}")

        # Execute the approved action
        return await self._execute_action(action)

    async def reject_action(self, action_id: str, reason: str = "") -> bool:
        """
        Reject a pending action

        YOU REJECT what you don't want AI to do
        """
        action = next((a for a in self.pending_actions if a.id == action_id), None)

        if not action:
            return False

        action.approval_status = ApprovalStatus.REJECTED

        logger.info(f"‚ùå Action rejected: {action.title} - Reason: {reason}")

        # Remove from pending
        self.pending_actions.remove(action)

        return True

    async def _execute_action(self, action: AIAction) -> bool:
        """Execute an approved action"""
        if action.action_type == "fix_bug":
            # Execute the fix
            # (implementation would go here)
            logger.info(f"üîß Executing fix: {action.title}")
            return True

        return False

    def _backup_file(self, file_path: str):
        """
        Backup file before modifying (for rollback)

        AI SAVES BACKUPS so you can undo changes
        """
        try:
            with open(file_path, 'r') as f:
                content = f.read()

            if file_path not in self.file_backups:
                self.file_backups[file_path] = []

            backup = {
                "timestamp": datetime.now(),
                "content": content
            }

            self.file_backups[file_path].append(backup)

            # Keep only backups within retention period
            cutoff = datetime.now() - timedelta(days=self.control_settings.keep_backups_days)
            self.file_backups[file_path] = [
                b for b in self.file_backups[file_path]
                if b["timestamp"] > cutoff
            ]

            logger.info(f"üíæ Backed up {file_path}")

        except Exception as e:
            logger.error(f"Backup failed for {file_path}: {e}")

    async def rollback_file(self, file_path: str, to_timestamp: Optional[datetime] = None) -> bool:
        """
        Rollback file to previous version

        YOU CAN UNDO anything AI did!
        """
        if file_path not in self.file_backups or not self.file_backups[file_path]:
            logger.error(f"No backups found for {file_path}")
            return False

        # Get the backup
        if to_timestamp:
            backup = next(
                (b for b in self.file_backups[file_path] if b["timestamp"] == to_timestamp),
                None
            )
        else:
            # Get most recent backup
            backup = self.file_backups[file_path][-1]

        if not backup:
            logger.error("Backup not found")
            return False

        try:
            # Restore file
            with open(file_path, 'w') as f:
                f.write(backup["content"])

            logger.info(f"‚Ü©Ô∏è  Rolled back {file_path} to {backup['timestamp']}")

            return True

        except Exception as e:
            logger.error(f"Rollback failed: {e}")
            return False

    async def auto_fix_issue(self, issue: SystemIssue) -> bool:
        """
        Automatically fix an issue (with approval if needed)

        AI can fix bugs - but YOU control when it needs to ask first!
        """
        if not issue.auto_fixable or not issue.file_path:
            return False

        # Create action for approval workflow
        action = AIAction(
            id=f"action_{datetime.now().timestamp()}",
            action_type="fix_bug",
            title=f"Fix {issue.severity} issue: {issue.title}",
            description=issue.description,
            risk_level=issue.severity,
            affected_files=[issue.file_path],
            code_diff=issue.suggested_fix,
            estimated_impact=f"Fix {issue.category} issue in {issue.file_path}",
            created_at=datetime.now()
        )

        # Check if approval needed
        if self._requires_approval(action):
            await self._request_approval(action)
            return False  # Wait for approval

        # Auto-approve
        action.approval_status = ApprovalStatus.AUTO_APPROVED

        logger.info(f"üîß Auto-fixing: {issue.title}")

        try:
            # STEP 1: Backup file before modifying (YOU CAN UNDO!)
            self._backup_file(issue.file_path)

            # STEP 2: Read current file
            with open(issue.file_path, 'r') as f:
                current_code = f.read()

            # STEP 3: Ask GPT-4 to generate fix
            prompt = f"""
Fix this issue in the code:

Issue: {issue.title}
Description: {issue.description}
Suggested Fix: {issue.suggested_fix}

Current Code:
```python
{current_code}
```

Return the COMPLETE fixed code. Do not explain, just return the fixed code.
"""

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are Meta-AI Guardian. Fix the issue perfectly."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2
            )

            fixed_code = response.choices[0].message.content

            # Remove markdown if present
            if "```python" in fixed_code:
                fixed_code = fixed_code.split("```python")[1].split("```")[0].strip()

            # STEP 4: Write fixed code
            with open(issue.file_path, 'w') as f:
                f.write(fixed_code)

            logger.info(f"   ‚úÖ Fixed: {issue.file_path} (backed up, can rollback!)")

            return True

        except Exception as e:
            logger.error(f"   ‚ùå Auto-fix failed: {e}")
            # Try to rollback if fix failed
            if self.control_settings.enable_automatic_rollback:
                await self.rollback_file(issue.file_path)
            return False

    async def suggest_improvements(self) -> List[ImprovementSuggestion]:
        """
        Analyze system and suggest improvements

        AI looks at everything and says "here's how to make it better"
        """
        logger.info("üí° Generating improvement suggestions...")

        # Analyze system patterns
        prompt = """
Based on Mindframe platform (AI agent automation):
- FastAPI backend
- Voice AI system
- Agent marketplace
- Auto-healing monitoring

Suggest 5 HIGH-IMPACT improvements that would:
1. Make it faster
2. More reliable
3. Better user experience
4. More secure
5. Easier to scale

For each suggestion, return JSON:
{
    "type": "performance|code_quality|feature|security",
    "title": "Brief title",
    "description": "Detailed description",
    "impact": "high|medium|low",
    "effort": "easy|medium|hard",
    "estimated_improvement": "Specific metric (e.g., 30% faster)"
}

Return array of 5 suggestions.
"""

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are Meta-AI Guardian. Suggest brilliant improvements."
                    },
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.7
            )

            result = json.loads(response.choices[0].message.content)
            suggestions_data = result.get("suggestions", [])

            suggestions = []
            for s in suggestions_data:
                suggestion = ImprovementSuggestion(
                    id=f"improvement_{datetime.now().timestamp()}",
                    type=s.get("type", "feature"),
                    title=s.get("title", ""),
                    description=s.get("description", ""),
                    impact=s.get("impact", "medium"),
                    effort=s.get("effort", "medium"),
                    estimated_improvement=s.get("estimated_improvement", "Unknown")
                )
                suggestions.append(suggestion)

            self.improvements.extend(suggestions)

            logger.info(f"üí° Generated {len(suggestions)} improvement suggestions")

            return suggestions

        except Exception as e:
            logger.error(f"Error generating improvements: {e}")
            return []

    async def monitor_performance(self) -> SystemHealth:
        """
        Monitor system performance in real-time

        Track everything, find bottlenecks, suggest optimizations
        """
        logger.info("üìä Monitoring system health...")

        # Simulate metrics (in production, collect real metrics)
        health = SystemHealth(
            timestamp=datetime.now(),
            health_score=95.0,  # Would calculate from real metrics
            performance_score=90.0,
            security_score=88.0,
            quality_score=92.0,
            issues_count=len(self.issues),
            critical_issues=sum(1 for i in self.issues if i.severity == "critical"),
            uptime_percentage=99.9,
            avg_response_time_ms=45.0,
            error_rate=0.01
        )

        # Check if scores are too low
        if health.health_score < 80:
            logger.warning(f"‚ö†Ô∏è  Health score low: {health.health_score}")

        if health.security_score < 85:
            logger.warning(f"üîí Security score low: {health.security_score}")

        return health

    async def check_dependencies(self) -> List[str]:
        """
        Check for outdated dependencies and security vulnerabilities

        Keep system up-to-date automatically
        """
        logger.info("üì¶ Checking dependencies...")

        # In production:
        # 1. Parse requirements.txt
        # 2. Check each package version
        # 3. Check for security vulnerabilities (GitHub Advisory Database)
        # 4. Suggest updates

        outdated = []

        # Simulated for example
        # In production, use pip-audit or safety library

        logger.info(f"üì¶ Found {len(outdated)} outdated dependencies")

        return outdated

    async def start_monitoring(self, interval_minutes: int = 60):
        """
        Start continuous monitoring

        Runs forever, checking system every N minutes
        """
        logger.info(f"üöÄ Starting Meta-AI Guardian (checking every {interval_minutes} min)")

        self.is_monitoring = True

        while self.is_monitoring:
            try:
                # 1. Check health
                health = await self.monitor_performance()

                # 2. Check dependencies
                await self.check_dependencies()

                # 3. If health is low, analyze codebase
                if health.health_score < 90:
                    logger.warning("Health low, running full analysis...")
                    # Would analyze specific files

                # 4. Auto-fix critical issues
                critical_issues = [i for i in self.issues if i.severity == "critical" and i.auto_fixable]

                for issue in critical_issues:
                    fixed = await self.auto_fix_issue(issue)
                    if fixed:
                        self.issues.remove(issue)

                # 5. Generate improvement suggestions (once per day)
                current_hour = datetime.now().hour
                if current_hour == 3:  # 3 AM
                    await self.suggest_improvements()

                # Wait for next check
                await asyncio.sleep(interval_minutes * 60)

            except Exception as e:
                logger.error(f"Monitoring error: {e}")
                await asyncio.sleep(60)  # Wait 1 min on error

    def stop_monitoring(self):
        """Stop continuous monitoring"""
        logger.info("‚èπÔ∏è  Stopping Meta-AI Guardian")
        self.is_monitoring = False

    async def generate_report(self) -> Dict[str, Any]:
        """
        Generate comprehensive system report

        Show everything: health, issues, improvements, trends
        """
        health = await self.monitor_performance()

        return {
            "timestamp": datetime.now().isoformat(),
            "health": health.dict(),
            "issues": {
                "total": len(self.issues),
                "critical": sum(1 for i in self.issues if i.severity == "critical"),
                "high": sum(1 for i in self.issues if i.severity == "high"),
                "by_category": {
                    "bugs": sum(1 for i in self.issues if i.category == "bug"),
                    "security": sum(1 for i in self.issues if i.category == "security"),
                    "performance": sum(1 for i in self.issues if i.category == "performance"),
                    "quality": sum(1 for i in self.issues if i.category == "quality")
                }
            },
            "improvements": {
                "total": len(self.improvements),
                "high_impact": sum(1 for i in self.improvements if i.impact == "high"),
                "easy_wins": sum(1 for i in self.improvements if i.effort == "easy" and i.impact == "high")
            },
            "pending_actions": {
                "total": len(self.pending_actions),
                "awaiting_approval": sum(
                    1 for a in self.pending_actions
                    if a.approval_status == ApprovalStatus.PENDING
                )
            },
            "control_settings": {
                "autonomy_level": self.control_settings.autonomy_level.value,
                "require_approval_for_critical": self.control_settings.require_approval_for_critical,
                "monitoring_interval_minutes": self.control_settings.monitoring_interval_minutes
            },
            "recommendations": [
                "Fix critical security issues first",
                "Implement high-impact, easy improvements",
                "Monitor performance metrics daily",
                "Keep dependencies updated",
                "Review pending actions regularly"
            ]
        }

    def get_pending_actions(self) -> List[AIAction]:
        """
        Get all pending actions awaiting YOUR approval

        See what AI wants to do before it does it
        """
        return [a for a in self.pending_actions if a.approval_status == ApprovalStatus.PENDING]

    def get_control_settings(self) -> ControlSettings:
        """
        Get current control settings

        See how much control you have over the AI
        """
        return self.control_settings

    def update_control_settings(self, new_settings: ControlSettings):
        """
        Update control settings

        YOU CHANGE how autonomous the AI is at any time
        """
        old_level = self.control_settings.autonomy_level
        self.control_settings = new_settings

        logger.info(
            f"üéöÔ∏è  Control settings updated: "
            f"{old_level.value} ‚Üí {new_settings.autonomy_level.value}"
        )

    def get_file_backups(self, file_path: str) -> List[Dict]:
        """
        Get all backups for a file

        See all versions you can rollback to
        """
        return self.file_backups.get(file_path, [])


# Usage Example
async def example_usage():
    """Example of using Meta-AI Guardian"""

    # Initialize
    guardian = MetaAIGuardian(openai_api_key="your-key")

    # 1. Analyze codebase
    files_to_check = [
        "src/api/main.py",
        "src/core/ai_agent_generator.py",
        "src/voice/voice_ai_engine.py"
    ]

    issues = await guardian.analyze_codebase(files_to_check)

    print(f"\nüîç Found {len(issues)} issues:")
    for issue in issues[:5]:  # Show first 5
        print(f"   [{issue.severity.upper()}] {issue.title}")
        print(f"      {issue.description}")
        if issue.auto_fixable:
            print(f"      ‚úÖ Can auto-fix")

    # 2. Auto-fix critical issues
    critical = [i for i in issues if i.severity == "critical" and i.auto_fixable]

    print(f"\nüîß Auto-fixing {len(critical)} critical issues...")
    for issue in critical:
        fixed = await guardian.auto_fix_issue(issue)
        if fixed:
            print(f"   ‚úÖ Fixed: {issue.title}")

    # 3. Get improvement suggestions
    improvements = await guardian.suggest_improvements()

    print(f"\nüí° Improvement suggestions:")
    for imp in improvements[:3]:
        print(f"   [{imp.impact.upper()}] {imp.title}")
        print(f"      Impact: {imp.estimated_improvement}")
        print(f"      Effort: {imp.effort}")

    # 4. Check system health
    health = await guardian.monitor_performance()

    print(f"\nüìä System Health:")
    print(f"   Overall: {health.health_score}/100")
    print(f"   Performance: {health.performance_score}/100")
    print(f"   Security: {health.security_score}/100")
    print(f"   Quality: {health.quality_score}/100")

    # 5. Generate report
    report = await guardian.generate_report()

    print(f"\nüìÑ Full Report:")
    print(json.dumps(report, indent=2))


if __name__ == "__main__":
    import asyncio
    asyncio.run(example_usage())
